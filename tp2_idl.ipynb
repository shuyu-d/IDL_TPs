{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2 (Exercice 2.6) - Regression linéaire \n",
    "\n",
    "Dans ce TP, nous implémentons les fonctions pour la résolution d'un problème de regression linéaire. \n",
    "Le but est de calculer le regresseur $\\beta$ dans les cas où le problème admet une unique solution.  \n",
    "\n",
    "Les données d'observation est généré aléatoirement par une fonction dédiée de Scikit-Learn (`sklearn`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation du jeu de données\n",
    "\n",
    "Dans cet example, on génère un jeu de données de manière aléatoire par `sklearn.datasets.make_regression`. Le nombre de variables dans $\\bar{x}$ est $p=1$, et le nombre d'échantillons observés est $n=100$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Xdata, y = datasets.make_regression(n_samples=30, n_features=1, noise=30) # \n",
    "Xdata, y = datasets.make_regression(n_samples=100, n_features=1, noise=30) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observer une paritie du jeu de données avec l'aide de Pandas DataFrame. Les `DataFrame`s de Pandas sont souvent plus facile à visualiser que les structures de données de NumPy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata_pd = pd.DataFrame( Xdata )\n",
    "Xdata_pd.head() # voir quelques lignes de la matrix Xdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser les données d'observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "ax.scatter(Xdata, y, marker='o', color='b')\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2.6 \n",
    "Le modèle linéaire recherché est de la forme $ \\bar{y} = {\\beta^{\\star}}^{T} \\bar{x} + \\epsilon$. Ici, dans le cas où $\\bar{x}$ contient une seule variable prédictive ($p=1$), le produit scaliare entre $\\beta^{\\star}$ et $\\bar{x}$ se réduit au simple produit $\\beta^{\\star} \\bar{x}$ où le regresseur $\\beta^{\\star} \\in \\mathbb{R}$ représente la pente recherchée du modèle.\n",
    "\n",
    "**Question:** dans quels cas ce problème admet-il une seul solution ? Aussi expliquer pour $p>1$ plus généralement. \n",
    "\n",
    "Ensuite, dans ces cas, trouver l'expression explicite pour la solution $\\beta^*:=(w^*, b^*)^{T} \\in\\mathbb{R}^{(p+1)}$ qui minimise \n",
    "$$ R(w,b) := \\| Xw + b - y \\|_2^2,$$\n",
    "en fonction de la matrix des données $X$, et du vecteur $y$ des observations de $\\bar{y}$. Voir les lignes contenant `A compléter`.\n",
    "\n",
    "Note: le vecteur du regresseur peut aussi être représenté par $\\beta:=(b, w)^T$. Selon la représentation du regresseur $\\beta$, la matrice des données $X$ (de taille $n\\times p$) est à ajuster pour être compatible avec le vecteur $\\beta$ pour l'expression de la solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Xdata.shape[0]\n",
    "X = Xdata # remove this line \n",
    "# Ajuster la matrice Xdata \n",
    "# X = ------ A COMPLÉTER ---------  \n",
    "pd.DataFrame(X).head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_closed_form(X, y):\n",
    "    # implémenter l'expression explicite de la solution recherchée \n",
    "    beta = np.array([1,1])\n",
    "    # ------ A COMPLÉTER -------\n",
    "    # beta = ... \n",
    "    return beta\n",
    "\n",
    "beta_closedform = beta_closed_form(X, y)\n",
    "print(beta_closedform.shape) # expected shape: (2,)\n",
    "print(beta_closedform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualiser** la solution : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "ax.scatter(X[:,1], y, marker='o', color='b')\n",
    "ax.plot(X[:,1], X.dot(beta_closedform), color='r')\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualiser** la solution sur le plan montrant les lignes de niveau de la fonction d'objective : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_one_variable(X, y, beta):\n",
    "    n = y.shape[0]\n",
    "    J = (1/(2*n)) * (np.sum((X.dot(beta) - y)**2))\n",
    "    return J\n",
    "beta0_vals = np.linspace(beta_closedform[0]*(-60), beta_closedform[0]*60, 100)\n",
    "beta1_vals = np.linspace(beta_closedform[1]*(-8), beta_closedform[1]*8, 100)\n",
    "J_vals = np.zeros(shape=(len(beta0_vals), len(beta1_vals)))\n",
    "for i in range(0, len(beta0_vals)):\n",
    "    for j in range(0, len(beta1_vals)):\n",
    "        J_vals[i,j] = compute_cost_one_variable(X, y, [[beta0_vals[i]], [beta1_vals[j]]])\n",
    "\n",
    "# print(J_vals)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "ax.contour(beta0_vals, beta1_vals, np.transpose(J_vals))\n",
    "ax.plot(beta_closedform[0], beta_closedform[1], marker='x', color='r');\n",
    "ax.set_xlabel(r'$\\beta_1$'); ax.set_ylabel(r'$\\beta_2$')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
